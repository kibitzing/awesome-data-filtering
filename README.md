# awesome-llm-data
A repository of information about data used in training large language models (LLMs)

## Models
### LLaMa 2
* (WIP) [Data used in LLaMa 2](https://github.com/kibitzing/awesome-llm-data/issues/1)


## Safety evaluation dataset
### **Bias**:
* [Bold](https://arxiv.org/pdf/2101.11718)
  * Used by: Llama 2
 
### **Truthfulness**: 
* [TruthfulQA](https://arxiv.org/pdf/2109.07958)
  * Used by: Llama 2
 
### **Toxicity**:
* [ToxiGen](https://arxiv.org/pdf/2203.09509)
  * Used by: Llama 2

## Model performance evaluation dataset

### Code
* [HumanEval](https://arxiv.org/pdf/2107.03374)
  * Used by: Llama 2
* [MBPP](https://arxiv.org/pdf/2108.07732)
  * Used by: Llama 2
### Commonsense reasoning
* [PIQA](https://arxiv.org/pdf/1911.11641)
  * Used by: Llama 2
* [SIQA](https://arxiv.org/pdf/1904.09728)
  * Used by: Llama 2
* [HellaSwag](https://arxiv.org/pdf/1905.07830)
  * Used by: Llama 2
* [WinoGrande](https://arxiv.org/pdf/1907.10641)
  * Used by: Llama 2
* [ARC eacy and challenge](https://arxiv.org/pdf/1803.05457)
  * Used by: Llama 2
* [OpenBookQA](https://arxiv.org/pdf/1809.02789)
  * Used by: Llama 2
* [CommonsenseQA](https://arxiv.org/pdf/1811.00937)
  * Used by: Llama 2
### World knowledge
* [NaturalQuestions](https://aclanthology.org/Q19-1026.pdf)
  * Used by: Llama 2
* [TriviaQA](https://arxiv.org/pdf/1705.03551)
  * Used by: Llama 2
### Reading comprehension
* [SQuAD](https://arxiv.org/pdf/1806.03822)
  * Used by: Llama 2
* [QuAC](https://aclanthology.org/D18-1241.pdf)
  * Used by: Llama 2
* [BoolQ](https://arxiv.org/pdf/1905.10044)
  * Used by: Llama 2
### Math
* [GSM8K](https://arxiv.org/pdf/2110.14168)
  * Used by: Llama 2
* [MATH](https://arxiv.org/pdf/2103.03874)
  * Used by: Llama 2
### Popular aggregated benchmarks
* [MMLU](https://arxiv.org/pdf/2009.03300)
  * Used by: Llama 2
* [Big Bench Hard (BBH](https://arxiv.org/pdf/2210.09261))
  * Used by: Llama 2
* [AGI Eval](https://arxiv.org/pdf/2304.06364)
  * Used by: Llama 2
